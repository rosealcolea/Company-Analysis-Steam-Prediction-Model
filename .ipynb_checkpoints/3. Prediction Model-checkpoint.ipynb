{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logo](./images/OPTIMISE.%20Logo%20(green).png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project I role play as a BI consultant from Optimise. using Steam as my client. I provide a full sales analysis & a sales prediction model based on key game features.\n",
    "\n",
    "This is Notebook 3 out of 4 of this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimise.\n",
    "BUSINESS INTELLIGENCE SOLUTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimise. uses data analysis to provide businesses a vision of their present operations and provides them with actionable advise based on meticulous analysis that produces tangible results.   \n",
    "\n",
    "The analysis focuses on these main areas:     \n",
    "- Product Analysis\n",
    "    - Performance\n",
    "    - Classification\n",
    "    - Pricing\n",
    "- Customer Analysis\n",
    "    - Customer Profile\n",
    "    - Customer Trends\n",
    "    - Customer Lifetime Value\n",
    "- Sales Analysis\n",
    "    - Date/Time Overview\n",
    "    - Discount Effeciency\n",
    "    - Projections\n",
    "    \n",
    "The deliverables to be expected are a comprehensive report with useful visualizations, combined with specific recommendations based on the results obtained from the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Model\n",
    "\n",
    "The goal of building a linear regression model is to devise a program that can predict the number of sales given certain parameters. For instance if a developer were to launch a `Single-Player`, `Adventure` game with `Controller Support` at a price of $20 how many copies could he expect to sell. \n",
    "\n",
    "This tool could be extremely useful for the company and I would like to add it in the package the company would be receiving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as sp\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.utils import resample\n",
    "from IPython.display import clear_output\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.read_csv(\"data/steam_cols_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping boolean columns by type\n",
    "\n",
    "platforms = ['linux', 'windows', 'mac']\n",
    "genres = ['Indie', 'Sports', 'Simulation', 'Strategy', 'Early Access', 'Casual',\n",
    "       'RPG', 'Free to Play', 'Adventure', 'Action', 'Racing']\n",
    "categories = ['Includes level editor', 'MMO', 'VR Support', 'Single-player',\n",
    "       'Controller Support', 'Online', 'Multi-Player', 'co-op', 'Local']\n",
    "tags = ['Nudity', 'Retro', 'Violent', 'Visual Novel', 'RPGMaker', 'Fighting',\n",
    "       'FPS', 'Female Protagonist', 'Board Game', 'Space', 'World War II',\n",
    "       'Platformer', 'Anime', 'Great Soundtrack', 'Massively Multiplayer',\n",
    "       'Open World', 'Sexual Content', 'Arcade', 'Gore', 'Pixel Graphics',\n",
    "       'Turn-Based', 'Music', 'Fantasy', 'Point & Click', 'Rogue-like',\n",
    "       'World War I', \"Shoot 'Em Up\", 'RTS', 'Story Rich', 'Hidden Object',\n",
    "       'Turn-Based Strategy', 'Survival', 'Match 3', 'Horror', 'Puzzle',\n",
    "       'Sci-fi', 'Tower Defense', 'VR', 'Management', '2D', 'Card Game',\n",
    "       'Multiplayer', 'Utilities', 'Shooter', 'War', 'Co-op', 'Zombies',\n",
    "       'Classic', 'Singleplayer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>name</th>\n",
       "      <th>release_date</th>\n",
       "      <th>english</th>\n",
       "      <th>developer</th>\n",
       "      <th>publisher</th>\n",
       "      <th>required_age</th>\n",
       "      <th>achievements</th>\n",
       "      <th>positive_ratings</th>\n",
       "      <th>negative_ratings</th>\n",
       "      <th>...</th>\n",
       "      <th>Free to Play</th>\n",
       "      <th>Includes level editor</th>\n",
       "      <th>VR Support</th>\n",
       "      <th>Single-player</th>\n",
       "      <th>MMO</th>\n",
       "      <th>Controller Support</th>\n",
       "      <th>Online</th>\n",
       "      <th>Multi-Player</th>\n",
       "      <th>co-op</th>\n",
       "      <th>Local</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>2000-11-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Valve</td>\n",
       "      <td>Valve</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124534</td>\n",
       "      <td>3339</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   appid            name release_date  english developer publisher  \\\n",
       "0     10  Counter-Strike   2000-11-01        1     Valve     Valve   \n",
       "\n",
       "   required_age  achievements  positive_ratings  negative_ratings  ...  \\\n",
       "0             0             0            124534              3339  ...   \n",
       "\n",
       "   Free to Play  Includes level editor VR Support  Single-player  MMO  \\\n",
       "0             0                      0          0              0    0   \n",
       "\n",
       "   Controller Support  Online  Multi-Player  co-op  Local  \n",
       "0                   0       1             1      0      1  \n",
       "\n",
       "[1 rows x 37 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['appid', 'name', 'release_date', 'english', 'developer', 'publisher',\n",
       "       'required_age', 'achievements', 'positive_ratings', 'negative_ratings',\n",
       "       'average_playtime', 'median_playtime', 'owners', 'price', 'windows',\n",
       "       'linux', 'mac', 'Strategy', 'Simulation', 'Racing', 'Adventure',\n",
       "       'Early Access', 'Action', 'Indie', 'Sports', 'RPG', 'Casual',\n",
       "       'Free to Play', 'Includes level editor', 'VR Support', 'Single-player',\n",
       "       'MMO', 'Controller Support', 'Online', 'Multi-Player', 'co-op',\n",
       "       'Local'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted Number of Sales Given a Certain Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "x = s['price'].values.reshape(-1,1)\n",
    "y = s['owners'].values.reshape(-1,1)\n",
    "\n",
    "model.fit(x,y)\n",
    "\n",
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.score(x,y)\n",
    "print(\"R2:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** The R2 score is absolutely minimal which means the model is perfectly inadequate to predict the number of sales based on the price. This makes sense since pricing, whilst important, it's not the biggest distinguishing factor among games nor the beggiest determinant of its purchase. \n",
    "\n",
    "This model is therefore useless and I shall have to find a more appropirate way of predicting sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistical Regression Model\n",
    "I will use a logistical regression model since I think it will be more suitable at taking into account categorical data and predicting the amount of sales ranges, which are also categorical in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted Number of Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100000-200000</th>\n",
       "      <th>1000000-2000000</th>\n",
       "      <th>10000000-20000000</th>\n",
       "      <th>100000000-200000000</th>\n",
       "      <th>20000-50000</th>\n",
       "      <th>200000-500000</th>\n",
       "      <th>2000000-5000000</th>\n",
       "      <th>20000000-50000000</th>\n",
       "      <th>50000-100000</th>\n",
       "      <th>500000-1000000</th>\n",
       "      <th>5000000-10000000</th>\n",
       "      <th>50000000-100000000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   100000-200000  1000000-2000000  10000000-20000000  100000000-200000000  \\\n",
       "0              0                0                  1                    0   \n",
       "1              0                0                  0                    0   \n",
       "2              0                0                  0                    0   \n",
       "3              0                0                  0                    0   \n",
       "4              0                0                  0                    0   \n",
       "\n",
       "   20000-50000  200000-500000  2000000-5000000  20000000-50000000  \\\n",
       "0            0              0                0                  0   \n",
       "1            0              0                0                  0   \n",
       "2            0              0                0                  0   \n",
       "3            0              0                0                  0   \n",
       "4            0              0                0                  0   \n",
       "\n",
       "   50000-100000  500000-1000000  5000000-10000000  50000000-100000000  \n",
       "0             0               0                 0                   0  \n",
       "1             0               0                 1                   0  \n",
       "2             0               0                 1                   0  \n",
       "3             0               0                 1                   0  \n",
       "4             0               0                 1                   0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(data=s['owners'], drop_first=True)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** I can already see that this model might also present its problems, since there's a significantly higher number of games that have between 7.500.000 and 15.000.000 owners, only those 2 categories are represented in the dummies data, which means it will only predecit one of these values. The answer is still valid but the the model wouldn't give us more information than getting the mode of onwers per genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[s[\"owners\"]==7500000].count()[0]/len(s)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** Upon closer observation, I realise that in fact not a majority of the games have 7.500.000 owners, which makes me wonder why the dummies reflect that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indie</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Simulation</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Early Access</th>\n",
       "      <th>Casual</th>\n",
       "      <th>RPG</th>\n",
       "      <th>Free to Play</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Action</th>\n",
       "      <th>Racing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Indie  Sports  Simulation  Strategy  Early Access  Casual  RPG  \\\n",
       "0      0       0           0         0             0       0    0   \n",
       "1      0       0           0         0             0       0    0   \n",
       "2      0       0           0         0             0       0    0   \n",
       "3      0       0           0         0             0       0    0   \n",
       "4      0       0           0         0             0       0    0   \n",
       "\n",
       "   Free to Play  Adventure  Action  Racing  \n",
       "0             0          0       1       0  \n",
       "1             0          0       1       0  \n",
       "2             0          0       1       0  \n",
       "3             0          0       1       0  \n",
       "4             0          0       1       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.get_dummies(data=s[genres], drop_first=True)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.963065558633424"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[\"Action\"].sum()/len(s)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** Similarly here, the `get_dummies` function seems to be returning interesting results that might affect my model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach Number 2\n",
    "Given the weird results obtained with the `get_dummies` function I have decided to use the data as is instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = s.drop([\"appid\", \"name\", \"release_date\", \"developer\", \"publisher\", \"owners\"], axis=1)\n",
    "y = s[\"owners\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# first model: logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    " \n",
    "log_model = LogisticRegression(max_iter=1000000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is: 0.7508771929824561\n",
      "Confusion Matrix:\n",
      " [[3636    1    0    0    0   66    0    0    0    1    0    0    1]\n",
      " [  43   49    1    1    1   96   69    1    1   26    0    0    2]\n",
      " [   0    0   13    3    0    0   10    7    0    0   13    1    1]\n",
      " [   0    0    0    3    0    0    0    2    0    0    0    1    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [ 384    7    0    0    0  191    6    0    0   11    1    0    0]\n",
      " [  11   31    5    8    1   53  112    6    1    8    8    0    2]\n",
      " [   0    0   10    2    0    0    1   18    1    0    5    1    1]\n",
      " [   0    0    0    2    0    0    0    0    0    0    0    0    0]\n",
      " [ 128   23    0    0    2  147   29    0    0   28    0    0    1]\n",
      " [   1   10    7    4    0    6   54    6    0    2   14    1    2]\n",
      " [   0    0    2    3    0    0    0    6    0    0    0    2    0]\n",
      " [   0    0    0    1    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Get score of the model\n",
    "score = log_model.score(X_test,y_test)\n",
    "\n",
    "# Predict using test data\n",
    "y_pred = log_model.predict(X_test)\n",
    "\n",
    "# Generate matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Accuracy score is:', score)\n",
    "print('Confusion Matrix:\\n',matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>predicted</th>\n",
       "      <th>success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17824</th>\n",
       "      <td>0-20000</td>\n",
       "      <td>0-20000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16815</th>\n",
       "      <td>0-20000</td>\n",
       "      <td>0-20000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19527</th>\n",
       "      <td>20000-50000</td>\n",
       "      <td>0-20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7973</th>\n",
       "      <td>50000-100000</td>\n",
       "      <td>20000-50000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579</th>\n",
       "      <td>50000-100000</td>\n",
       "      <td>100000-200000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9390</th>\n",
       "      <td>0-20000</td>\n",
       "      <td>0-20000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>0-20000</td>\n",
       "      <td>0-20000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23880</th>\n",
       "      <td>0-20000</td>\n",
       "      <td>0-20000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12896</th>\n",
       "      <td>20000-50000</td>\n",
       "      <td>20000-50000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12731</th>\n",
       "      <td>100000-200000</td>\n",
       "      <td>0-20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5415 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            original      predicted  success\n",
       "17824        0-20000        0-20000        1\n",
       "16815        0-20000        0-20000        1\n",
       "19527    20000-50000        0-20000        0\n",
       "7973    50000-100000    20000-50000        0\n",
       "4579    50000-100000  100000-200000        0\n",
       "...              ...            ...      ...\n",
       "9390         0-20000        0-20000        1\n",
       "3244         0-20000        0-20000        1\n",
       "23880        0-20000        0-20000        1\n",
       "12896    20000-50000    20000-50000        1\n",
       "12731  100000-200000        0-20000        0\n",
       "\n",
       "[5415 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a data frame to compare the original and predicted results\n",
    "compare = {\"original\" : y_test,\n",
    "           \"predicted\" : log_model.predict(X_test)}\n",
    "\n",
    "c = pd.DataFrame(compare)\n",
    "\n",
    "c[\"success\"] = np.where(c[\"original\"]==c[\"predicted\"], 1, 0)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.08771929824562"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[\"success\"].sum()/len(c)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With an accuracy score of 0.7508771929824561 our model has an relatively hight accuracy as shown in the results\n",
      "Accurate results: 3685\n",
      "Missed results: 44\n"
     ]
    }
   ],
   "source": [
    "# Summary \n",
    "print(\"With an accuracy score of\", score, \"our model has an relatively hight accuracy as shown in the results\")\n",
    "print(\"Accurate results:\", matrix[0][0] + matrix[1][1])\n",
    "print(\"Missed results:\",  matrix[0][1] + matrix[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted Number of Sales per Genre and Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign values\n",
    "x = s.drop([\"appid\", \"name\", \"release_date\", \"developer\", \"publisher\", 'required_age', 'achievements', 'positive_ratings', 'negative_ratings',\n",
    "       'average_playtime', 'median_playtime', 'owners', 'linux', 'mac', 'windows', 'VR Support', 'Single-player',\n",
    "       'Controller Support', 'Online', 'Multi-Player', 'co-op', 'Local'], axis=1)\n",
    "y = s[\"owners\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# Generate the model\n",
    "genre_model = LogisticRegression(max_iter=1000000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is: 0.6818097876269621\n",
      "Confusion Matrix:\n",
      " [[3677    2    2    0    0   20    0    0    0    6    2    0]\n",
      " [ 276    0    1    0    0    4    0    1    0    4    0    0]\n",
      " [  50    0    0    0    0    3    0    0    0    2    0    0]\n",
      " [   2    0    0    0    0    0    0    1    0    0    0    0]\n",
      " [   0    0    0    0    0    1    0    0    0    0    0    0]\n",
      " [ 617    0    0    0    0    9    0    0    0    4    1    0]\n",
      " [ 237    0    2    0    0   10    0    1    0    4    0    0]\n",
      " [  30    0    1    0    0    3    0    1    0    3    2    0]\n",
      " [   0    0    0    0    0    1    0    0    0    0    0    0]\n",
      " [ 308    0    2    0    0   10    0    0    0    5    1    0]\n",
      " [  83    0    1    0    0    4    0    4    0    2    0    0]\n",
      " [  13    0    0    0    0    0    0    2    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# Get score of the model\n",
    "score = genre_model.score(X_test,y_test)\n",
    "\n",
    "# Predict using test data\n",
    "y_pred = genre_model.predict(X_test)\n",
    "\n",
    "# Generate matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Accuracy score is:', score)\n",
    "print('Confusion Matrix:\\n',matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With an accuracy score of 0.6818097876269621 our model has a medium accuracy as shown in the results\n",
      "Accurate results: 3677\n",
      "Missed results: 278\n"
     ]
    }
   ],
   "source": [
    "print(\"With an accuracy score of\", score, \"our model has a medium accuracy as shown in the results\")\n",
    "print(\"Accurate results:\", matrix[0][0] + matrix[1][1])\n",
    "print(\"Missed results:\",  matrix[0][1] + matrix[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted Number of Sales per Category and Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign values\n",
    "x = s.drop([\"appid\", \"name\", \"release_date\", \"developer\", \"publisher\", 'required_age', 'achievements', 'positive_ratings', 'negative_ratings',\n",
    "       'average_playtime', 'median_playtime', 'owners', 'linux', 'mac', 'windows', 'Strategy', 'Free to Play', 'Sports', 'Early Access',\n",
    "       'Racing', 'RPG', 'Action', 'Indie', 'Casual', 'Simulation', 'Adventure',\n",
    "       'Includes level editor', 'MMO'], axis=1)\n",
    "y = s[\"owners\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# Generate the model\n",
    "category_model = LogisticRegression(max_iter=1000000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is: 0.6932594644506002\n",
      "Confusion Matrix:\n",
      " [[3754    0    1    0    0    0    0    0    0    2    0]\n",
      " [ 278    0    0    0    0    0    0    0    0    0    0]\n",
      " [  60    0    0    0    0    0    0    0    0    0    0]\n",
      " [   1    0    0    0    0    0    0    0    0    0    0]\n",
      " [   1    0    0    0    0    0    0    0    0    0    0]\n",
      " [ 567    0    0    0    0    0    0    0    0    0    0]\n",
      " [ 258    0    0    0    0    0    0    0    0    0    0]\n",
      " [  35    0    0    0    0    0    0    0    0    0    0]\n",
      " [ 357    0    0    0    0    0    0    0    0    0    0]\n",
      " [  95    0    0    0    0    0    0    0    0    0    0]\n",
      " [   6    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# Get score of the model\n",
    "score = category_model.score(X_test,y_test)\n",
    "\n",
    "# Predict using test data\n",
    "y_pred = category_model.predict(X_test)\n",
    "\n",
    "# Generate matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Accuracy score is:', score)\n",
    "print('Confusion Matrix:\\n',matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With an accuracy score of 0.6932594644506002 our model has a medium accuracy as shown in the results\n",
      "Accurate results: 3754\n",
      "Missed results: 278\n"
     ]
    }
   ],
   "source": [
    "print(\"With an accuracy score of\", score, \"our model has a medium accuracy as shown in the results\")\n",
    "print(\"Accurate results:\", matrix[0][0] + matrix[1][1])\n",
    "print(\"Missed results:\",  matrix[0][1] + matrix[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted Number of Sales per Platform and Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign values\n",
    "x = s.drop([\"appid\", \"name\", \"release_date\", \"developer\", \"publisher\", 'required_age', 'achievements', 'positive_ratings', 'negative_ratings',\n",
    "       'average_playtime', 'median_playtime', 'owners', 'VR Support', 'Single-player',\n",
    "       'Controller Support', 'Online', 'Multi-Player', 'co-op', 'Local', 'Strategy', 'Free to Play', 'Sports', 'Early Access',\n",
    "       'Racing', 'RPG', 'Action', 'Indie', 'Casual', 'Simulation', 'Adventure',\n",
    "       'Includes level editor', 'MMO'], axis=1)\n",
    "y = s[\"owners\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# Generate the model\n",
    "platform_model = LogisticRegression(max_iter=1000000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is: 0.6823638042474608\n",
      "Confusion Matrix:\n",
      " [[3695    0    0    0    0    0    0    0    0    0    4    0    0]\n",
      " [ 291    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [  52    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   6    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   1    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [ 626    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [ 243    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [  49    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   2    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [ 336    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [ 103    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   6    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   1    0    0    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# Get score of the model\n",
    "score = platform_model.score(X_test,y_test)\n",
    "\n",
    "# Predict using test data\n",
    "y_pred = platform_model.predict(X_test)\n",
    "\n",
    "# Generate matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Accuracy score is:', score)\n",
    "print('Confusion Matrix:\\n',matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With an accuracy score of 0.6823638042474608 our model has a medium accuracy as shown in the results\n",
      "Accurate results: 3695\n",
      "Missed results: 291\n"
     ]
    }
   ],
   "source": [
    "print(\"With an accuracy score of\", score, \"our model has a medium accuracy as shown in the results\")\n",
    "print(\"Accurate results:\", matrix[0][0] + matrix[1][1])\n",
    "print(\"Missed results:\",  matrix[0][1] + matrix[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted Number of Sales per Genre, Category, Platform and Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign values\n",
    "x = s.drop([\"appid\", \"name\", \"release_date\",'english', \"developer\", \"publisher\", 'required_age', 'achievements', 'positive_ratings', 'negative_ratings',\n",
    "       'average_playtime', 'median_playtime', 'owners'], axis=1)\n",
    "y = s[\"owners\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# Generate the model\n",
    "all_model = LogisticRegression(max_iter=1000000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is: 0.686241920590951\n",
      "Confusion Matrix:\n",
      " [[3696    0    2    0   10    0    0    0    3    2    0]\n",
      " [ 275    0    0    0   10    3    3    0    3    0    0]\n",
      " [  47    0    2    0    3    1    2    0    2    2    0]\n",
      " [   3    0    0    0    0    0    2    0    1    0    0]\n",
      " [ 603    0    0    0   10    1    0    0    3    2    0]\n",
      " [ 234    0    0    0    6    1    2    0    7    4    0]\n",
      " [  33    0    1    0    3    1    0    0    2    2    0]\n",
      " [   0    0    0    0    1    0    1    0    0    0    0]\n",
      " [ 298    2    0    0    2    0    5    0    3    1    0]\n",
      " [  92    0    0    0    2    0    7    0    3    4    1]\n",
      " [   3    0    0    0    1    1    1    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# Get score of the model\n",
    "score = all_model.score(X_test,y_test)\n",
    "\n",
    "# Predict using test data\n",
    "y_pred = all_model.predict(X_test)\n",
    "\n",
    "# Generate matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Accuracy score is:', score)\n",
    "print('Confusion Matrix:\\n',matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With an accuracy score of 0.686241920590951 our model has a medium accuracy as shown in the results\n",
      "Accurate results: 3696\n",
      "Missed results: 275\n"
     ]
    }
   ],
   "source": [
    "print(\"With an accuracy score of\", score, \"our model has a medium accuracy as shown in the results\")\n",
    "print(\"Accurate results:\", matrix[0][0] + matrix[1][1])\n",
    "print(\"Missed results:\",  matrix[0][1] + matrix[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** Similarly here, the `get_dummies` function seems to be returning interesting results that might affect my model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study: Ubisoft\n",
    "In this scenario I'm going to build a model that predicts the number of sales given a certain genre, category, platform and price, but only for games published by Ubisoft (one of the top publishers on Steam). This will hopefully produce more consistent results and a better model, since it eliminates the wide range of games that see no success despite having similar parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign values\n",
    "x = s[s[\"publisher\"]==\"Ubisoft\"].drop([\"appid\", \"name\", \"release_date\",'english', \"developer\", \"publisher\", 'required_age', 'achievements', 'positive_ratings', 'negative_ratings',\n",
    "       'average_playtime', 'median_playtime', 'owners'], axis=1)\n",
    "y = s[s[\"publisher\"]==\"Ubisoft\"][\"owners\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# Generate the model\n",
    "ubisoft_model = LogisticRegression(max_iter=1000000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is: 0.30434782608695654\n",
      "Confusion Matrix:\n",
      " [[0 1 0 0 0 2 0 0 0]\n",
      " [0 0 0 0 0 5 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 6 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 1]\n",
      " [0 1 0 0 0 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Get score of the model\n",
    "score = ubisoft_model.score(X_test,y_test)\n",
    "\n",
    "# Predict using test data\n",
    "y_pred = ubisoft_model.predict(X_test)\n",
    "\n",
    "# Generate matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Accuracy score is:', score)\n",
    "print('Confusion Matrix:\\n',matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With an accuracy score of 0.30434782608695654 our model has a medium accuracy as shown in the results\n",
      "Accurate results: 0\n",
      "Missed results: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"With an accuracy score of\", score, \"our model has a medium accuracy as shown in the results\")\n",
    "print(\"Accurate results:\", matrix[0][0] + matrix[1][1])\n",
    "print(\"Missed results:\",  matrix[0][1] + matrix[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** I am surprised at the result. I expected the accuracy of this model to be higher, due too lower variability. However, there are only 111 games published by Ubisoft so the low number of entries might be affecting the model significantly more than anticipated. Or perhaps there's still a lot of variability among games even by the same publisher, and the low number of entris makes it even harder to make proper predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[s[\"publisher\"]==\"Ubisoft\"][\"Action\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Function that Creates a Model\n",
    "I'm going to change my strategy and instead of trying to create a good model that takes into account all the different features, and then pass said features to predict a result, I'm going to create a function that passes certain features and then build a specific model with those parameters. This will also make it so that the model will have significantly less variables, which is a much more suitable environement for the Logistical Regression Model to work properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Number of Sales based on Genre and Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_model(genre, category):\n",
    "    # Assign values\n",
    "    x = s[s[genre]==1]\n",
    "    x = x[x[category]==1]\n",
    "    #x = x[x[\"price\"]==price]\n",
    "    x = x.drop([\"appid\", \"name\", \"release_date\",'english', \"developer\", \"publisher\", 'required_age', 'achievements', 'positive_ratings', 'negative_ratings',\n",
    "       'average_playtime', 'median_playtime', 'owners'], axis=1)\n",
    "    y = s[s[genre]==1]\n",
    "    #x = y[y[\"price\"]==price]\n",
    "    y = y[y[category]==1][\"owners\"]\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "    # Generate the model\n",
    "    model = LogisticRegression(max_iter=1000000).fit(X_train, y_train)\n",
    "    # Get score of the model\n",
    "    score = model.score(X_test,y_test)\n",
    "    print(\"Accuracy score:\", round(score*100, 2), \"%\")\n",
    "    # Predict using test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Generate matrix\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    return list(sp.mode(y_pred)[0])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests / Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Category and Genre options:\n",
    "\n",
    "platforms = `'linux', 'windows', 'mac'`\n",
    "\n",
    "genres = `'Indie', 'Sports', 'Simulation', 'Strategy', 'Early Access', 'Casual',\n",
    "       'RPG', 'Free to Play', 'Adventure', 'Action', 'Racing'`\n",
    "       \n",
    "categories = `'Includes level editor', 'MMO', 'VR Support', 'Single-player',\n",
    "       'Controller Support', 'Online', 'Multi-Player', 'co-op', 'Local'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 67.75 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0-20000'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_model(\"Action\", \"Local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 47.27 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0-20000'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_model(\"RPG\", \"Online\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Version 2: Goal - Improve accuracy score\n",
    "The accuracy score of the previous model is not high enough, so I'm going to work on improving my model until it reaches an accuracy of around 90%. The first thing I will be trying is reducing the number of columns that I input in the model by dropping all the unecessary ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_model_2(genre, category):\n",
    "    # Assign values x\n",
    "    x = s[s[genre]==1]\n",
    "    x = x[x[category]==1]\n",
    "    x.drop([\"appid\", \"name\", \"release_date\",'english', \"developer\", \"publisher\", 'required_age', 'achievements', 'positive_ratings',\n",
    "            'negative_ratings', 'average_playtime', 'median_playtime', 'owners', \"price\"], axis=1, inplace=True)\n",
    "    x.drop(platforms, axis=1, inplace=True)\n",
    "    genres_copy = genres.copy()\n",
    "    genres_copy.remove(genre)\n",
    "    x.drop(genres_copy, axis=1, inplace=True)\n",
    "    cat_copy = categories.copy()\n",
    "    cat_copy.remove(category)\n",
    "    x.drop(cat_copy, axis=1, inplace=True)\n",
    "    # Assign values y\n",
    "    y = s[s[genre]==1]\n",
    "    y = y[y[category]==1][\"owners\"]\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "    # Generate the model\n",
    "    model = LogisticRegression(max_iter=1000000).fit(X_train, y_train)\n",
    "    # Get score of the model\n",
    "    score = model.score(X_test,y_test)\n",
    "    print(\"Accuracy score:\", round(score*100, 2), \"%\")\n",
    "    # Predict using test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Generate matrix\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(matrix)\n",
    "    return list(sp.mode(y_pred)[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 68.41 %\n",
      "[[1540    0    0    0    0    0    0    0    0    0    0]\n",
      " [ 105    0    0    0    0    0    0    0    0    0    0]\n",
      " [  32    0    0    0    0    0    0    0    0    0    0]\n",
      " [   4    0    0    0    0    0    0    0    0    0    0]\n",
      " [ 233    0    0    0    0    0    0    0    0    0    0]\n",
      " [ 112    0    0    0    0    0    0    0    0    0    0]\n",
      " [  19    0    0    0    0    0    0    0    0    0    0]\n",
      " [   1    0    0    0    0    0    0    0    0    0    0]\n",
      " [ 147    0    0    0    0    0    0    0    0    0    0]\n",
      " [  52    0    0    0    0    0    0    0    0    0    0]\n",
      " [   6    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0-20000'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_model_2(\"Action\", \"Local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 73.39 %\n",
      "[[2764    0    0    0    0    0    0    0    0]\n",
      " [ 175    0    0    0    0    0    0    0    0]\n",
      " [   8    0    0    0    0    0    0    0    0]\n",
      " [ 389    0    0    0    0    0    0    0    0]\n",
      " [ 145    0    0    0    0    0    0    0    0]\n",
      " [  18    0    0    0    0    0    0    0    0]\n",
      " [ 220    0    0    0    0    0    0    0    0]\n",
      " [  45    0    0    0    0    0    0    0    0]\n",
      " [   2    0    0    0    0    0    0    0    0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0-20000'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_model_2(\"Indie\", \"Local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 73.89 %\n",
      "[[2750    0    0    0    0    0    0    0    0]\n",
      " [ 170    0    0    0    0    0    0    0    0]\n",
      " [  18    0    0    0    0    0    0    0    0]\n",
      " [ 372    0    0    0    0    0    0    0    0]\n",
      " [ 153    0    0    0    0    0    0    0    0]\n",
      " [  12    0    0    0    0    0    0    0    0]\n",
      " [ 203    0    0    0    0    0    0    0    0]\n",
      " [  43    0    0    0    0    0    0    0    0]\n",
      " [   1    0    0    0    0    0    0    0    0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0-20000'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_model_2(\"Indie\", \"Single-player\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 18.59 %\n",
      "[[29  0  0  0  0  0  0  0  0  0]\n",
      " [13  0  0  0  0  0  0  0  0  0]\n",
      " [ 9  0  0  0  0  0  0  0  0  0]\n",
      " [19  0  0  0  0  0  0  0  0  0]\n",
      " [31  0  0  0  0  0  0  0  0  0]\n",
      " [13  0  0  0  0  0  0  0  0  0]\n",
      " [29  0  0  0  0  0  0  0  0  0]\n",
      " [11  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0-20000'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_model_2(\"Free to Play\", \"Multi-Player\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 48.94 %\n",
      "[[46  0  0  0  0  0]\n",
      " [ 7  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0]\n",
      " [14  0  0  0  0  0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0-20000'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_model_2(\"Racing\", \"Multi-Player\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** After running numerous test, my accuracy score hasn't imporved signficantly. Morevoer, I can see that the major problem I have, as shown by the confusion matrix, is that I have too many outcomes. \n",
    "\n",
    "What I will attempt to do is check the the amount of games that have each outcome, and reassign the ones that barely have any, and/or group together certain outcomes (number of sales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10000000-20000000', '5000000-10000000', '2000000-5000000',\n",
       "       '20000000-50000000', '100000000-200000000', '50000000-100000000',\n",
       "       '20000-50000', '500000-1000000', '100000-200000', '50000-100000',\n",
       "       '1000000-2000000', '200000-500000', '0-20000'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[\"owners\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0-20000                18596\n",
       "20000-50000             3059\n",
       "50000-100000            1695\n",
       "100000-200000           1386\n",
       "200000-500000           1272\n",
       "500000-1000000           513\n",
       "1000000-2000000          288\n",
       "2000000-5000000          193\n",
       "5000000-10000000          46\n",
       "10000000-20000000         21\n",
       "20000000-50000000          3\n",
       "50000000-100000000         2\n",
       "100000000-200000000        1\n",
       "Name: owners, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[\"owners\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** I can see how and why the model was always predicting that the game would receive 10000 views, it's because there's a staggering amount of games that have received that many sales. I can easily see how I can create 3 groups out of these numbers and that will reduce the number of outcomes from 13 to 3, which should give me a significantly higher accuracy, and hopefully we could sometimes obtain a prediction for something other than 10000.\n",
    "\n",
    "Firstly however, I want to undo a step I did during the data cleaning process, which was to transform the the original sales ranges into an integer by finding the mean of each range. The data type of the target column does not matter for this type of model building so it will fit more nicely I think, to have ranges instead of specific outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10000000-20000000', '5000000-10000000', '2000000-5000000',\n",
       "       '20000000-50000000', '100000000-200000000', '50000000-100000000',\n",
       "       '20000-50000', '500000-1000000', '100000-200000', '50000-100000',\n",
       "       '1000000-2000000', '200000-500000', '0-20000'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[\"owners\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0-20000                18596\n",
       "20000-50000             3059\n",
       "50000-100000            1695\n",
       "100000-200000           1386\n",
       "200000-500000           1272\n",
       "500000-1000000           513\n",
       "1000000-2000000          288\n",
       "2000000-5000000          193\n",
       "5000000-10000000          46\n",
       "10000000-20000000         21\n",
       "20000000-50000000          3\n",
       "50000000-100000000         2\n",
       "100000000-200000000        1\n",
       "Name: owners, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[\"owners\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10000000-20000000', '5000000-10000000', '2000000-5000000',\n",
       "       '20000000-50000000', '100000000-200000000', '50000000-100000000',\n",
       "       '20000-50000', '500000-1000000', '100000-200000', '50000-100000',\n",
       "       '1000000-2000000', '200000-500000', '0-20000'], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[\"owners\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reassign_owners(row):\n",
    "    a = [\"20000-50000\", \"50000-100000\", \"100000-200000\", \"200000-500000\"]\n",
    "    b = [\"500000-1000000\", \"1000000-2000000\", \"2000000-5000000\", \"5000000-10000000\", \"10000000-20000000\", \n",
    "         \"20000000-50000000\", \"50000000-100000000\", \"100000000-200000000\"]\n",
    "    if row in a:\n",
    "        row = \"20000-500000\"\n",
    "    elif row in b:\n",
    "        row = \"500000+\"\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[\"owners\"] = s[\"owners\"].apply(lambda x: reassign_owners(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0-20000         18596\n",
       "20000-500000     7412\n",
       "500000+          1067\n",
       "Name: owners, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[\"owners\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying It  Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 67.57 %\n",
      "[[1521    0    0]\n",
      " [ 629    0    0]\n",
      " [ 101    0    0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0-20000'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_model_2(\"Action\", \"Local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 72.7 %\n",
      "[[2738    0    0]\n",
      " [ 953    0    0]\n",
      " [  75    0    0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0-20000'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_model_2(\"Indie\", \"Local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 73.51 %\n",
      "[[2736    0    0]\n",
      " [ 916    0    0]\n",
      " [  70    0    0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0-20000'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_model_2(\"Indie\", \"Single-player\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 64.1 %\n",
      "[[  0  22   0]\n",
      " [  0 100   0]\n",
      " [  0  34   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'20000-500000'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_model_2(\"Free to Play\", \"Multi-Player\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 50.0 %\n",
      "[[47  0  0]\n",
      " [40  0  0]\n",
      " [ 7  0  0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0-20000'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_model_2(\"Racing\", \"Multi-Player\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** The accurancy scores haven't improved. Upon closer observation at the confusion matrixes, I observe that all the values predicted are always the same. This is due to the massive imbalance in my data set. A big majority of the games will have between 0 and 20.000 sales, which inevitably skews the predictions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with Imbalance\n",
    "\n",
    "In order to build an accurate model that won't be determined by my data set, but will weigh the features independetly of their representaiton, I will rebalance it before running the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0-20000         18596\n",
       "20000-500000     7412\n",
       "500000+          1067\n",
       "Name: owners, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[\"owners\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000-500000    18596\n",
       "0-20000         18596\n",
       "500000+         18596\n",
       "Name: owners, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deal with scaling\n",
    "majority = s[s['owners'] == \"0-20000\"]\n",
    "minority1 = s[s['owners'] == \"20000-500000\"]\n",
    "minority2 = s[s['owners'] == \"500000+\"]\n",
    " \n",
    "# Downsample majority class\n",
    "minority1_upsampled = resample(minority1, n_samples=len(majority)) #random_state=123\n",
    "minority2_upsampled = resample(minority2, n_samples=len(majority))\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "owners_upsampled = pd.concat([minority1_upsampled, minority2_upsampled, majority])\n",
    "\n",
    "owners_upsampled['owners'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_model_balanced(genre, category):\n",
    "    # Assign values x\n",
    "    x = owners_upsampled[owners_upsampled[genre]==1]\n",
    "    x = x[x[category]==1]\n",
    "    x.drop([\"appid\", \"name\", \"release_date\",'english', \"developer\", \"publisher\", 'required_age', 'achievements', 'positive_ratings',\n",
    "            'negative_ratings', 'average_playtime', 'median_playtime', 'owners', \"price\"], axis=1, inplace=True)\n",
    "    x.drop(platforms, axis=1, inplace=True)\n",
    "    genres_copy = genres.copy()\n",
    "    genres_copy.remove(genre)\n",
    "    x.drop(genres_copy, axis=1, inplace=True)\n",
    "    cat_copy = categories.copy()\n",
    "    cat_copy.remove(category)\n",
    "    x.drop(cat_copy, axis=1, inplace=True)\n",
    "    # Assign values y\n",
    "    y = owners_upsampled[owners_upsampled[genre]==1]\n",
    "    y = y[y[category]==1][\"owners\"]\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "    # Generate the model\n",
    "    model = LogisticRegression(max_iter=1000000).fit(X_train, y_train)\n",
    "    # Get score of the model\n",
    "    score = model.score(X_test,y_test)\n",
    "    print(\"Accuracy score:\", round(score*100, 2), \"%\")\n",
    "    # Predict using test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Generate matrix\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(matrix)\n",
    "    return list(sp.mode(y_pred)[0])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests / Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 37.42 %\n",
      "[[   0    0 1570]\n",
      " [   0    0 1486]\n",
      " [   0    0 1827]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'500000+'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_model_balanced(\"Action\", \"Local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 43.8 %\n",
      "[[2774    0    0]\n",
      " [2302    0    0]\n",
      " [1257    0    0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0-20000'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_model_balanced(\"Indie\", \"Local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 43.38 %\n",
      "[[2716    0    0]\n",
      " [2297    0    0]\n",
      " [1248    0    0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0-20000'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_model_balanced(\"Indie\", \"Single-player\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 72.36 %\n",
      "[[  0   0  32]\n",
      " [  0   0 217]\n",
      " [  0   0 652]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'500000+'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_model_balanced(\"Free to Play\", \"Multi-Player\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 58.51 %\n",
      "[[55  0  0]\n",
      " [35  0  0]\n",
      " [ 4  0  0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0-20000'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_model_2(\"Racing\", \"Multi-Player\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** The accuracy scores have dismished despite improving the model. This further proves that the biggest issue with this model is the huge variability of the data. The sales a game recieves are simply not determined by its genre or category.\n",
    "\n",
    "However, for the illustrative purposes of this excercise, I will use the model despite it being imperfect. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-Friendly Model\n",
    "I will now create an user-friendly interface that takes the user's input and build's the model according to the described specifications. \n",
    "\n",
    "I will also be adding visual elements to it, and possibily addind the option of having muliple genres and categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_model(platform, genre, category):\n",
    "    # Assign values x\n",
    "    x = s[s[genre]==1]\n",
    "    x = x[x[category]==1]\n",
    "    x.drop([\"appid\", \"name\", \"release_date\",'english', \"developer\", \"publisher\", 'required_age', 'achievements', 'positive_ratings',\n",
    "            'negative_ratings', 'average_playtime', 'median_playtime', 'owners', \"price\"], axis=1, inplace=True)\n",
    "    platforms_copy = platforms.copy()\n",
    "    platforms_copy.remove(platform)\n",
    "    x.drop(platforms_copy, axis=1, inplace=True)\n",
    "    genres_copy = genres.copy()\n",
    "    genres_copy.remove(genre)\n",
    "    x.drop(genres_copy, axis=1, inplace=True)\n",
    "    cat_copy = categories.copy()\n",
    "    cat_copy.remove(category)\n",
    "    x.drop(cat_copy, axis=1, inplace=True)\n",
    "    # Assign values y\n",
    "    y = s[s[genre]==1]\n",
    "    y = y[y[category]==1][\"owners\"]\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "    # Generate the model\n",
    "    model = LogisticRegression(max_iter=1000000).fit(X_train, y_train)\n",
    "    # Get score of the model\n",
    "    score = model.score(X_test,y_test)\n",
    "    # Predict using test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Generate matrix\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"\\nThe expected amounts of sales for this game fall in the range\", list(sp.mode(y_pred)[0])[0])\n",
    "    print(\"With an accuracy score of\", round(score*100, 2), \"%\")\n",
    "    #Data Visualization\n",
    "    return #plt.plot(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    print(\"This model will return the predicted number of sales based on key features like platform, genre, and categories.\\n\")\n",
    "    #n = input(\"How many features do you want to test?\")\n",
    "    print(\"\\nPlatforms:\", platforms, \"\\n\")\n",
    "    platform = input(\"Choose Platform:\\n\")\n",
    "    print(\"\\nGenres:\", genres, \"\\n\")\n",
    "    genre = input(\"Choose Genre:\\n\")\n",
    "    print(\"\\nCategories\", categories, \"\\n\")\n",
    "    category = input(\"Choose Category:\\n\")\n",
    "    result = logistic_regression_model(platform, genre, category)\n",
    "    return print(\"\\n\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model will return the predicted number of sales based on key features like platform, genre, and categories.\n",
      "\n",
      "\n",
      "Platforms: ['linux', 'windows', 'mac'] \n",
      "\n",
      "Choose Platform:\n",
      "windows\n",
      "\n",
      "Genres: ['Indie', 'Sports', 'Simulation', 'Strategy', 'Early Access', 'Casual', 'RPG', 'Free to Play', 'Adventure', 'Action', 'Racing'] \n",
      "\n",
      "Choose Genre:\n",
      "Action\n",
      "\n",
      "Categories ['Includes level editor', 'MMO', 'VR Support', 'Single-player', 'Controller Support', 'Online', 'Multi-Player', 'co-op', 'Local'] \n",
      "\n",
      "Choose Category:\n",
      "Local\n",
      "\n",
      "The expected amounts of sales for this game fall in the range 0-20000\n",
      "With an accuracy score of 67.88 %\n",
      "\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** I am happy with the current model, despite its questionable accuracy. However, I still want to take a shot at improving it in the following ways:\n",
    "\n",
    "1. Making the target binary. Even if this will reduce the usefulness of the result, it will improve the overall performance of the model.\n",
    "2. Attempting to include developer or publisher in the features being tested. This wasn't done from the start because the unique variables in these categories is unsurmountable high. However, simply by dividing both in 2 groups (more than 10 games vs less than 10 games, for example) could improve the model since developer and publisher do have a significant effect on sales.\n",
    "3. Try a different model altogether, potentially better fitted for this situation. Namely a Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary\n",
    "I will be using an upsampling technique to balance out the target data. I will devide this one in 2 groups, `0-20000` and `20000+`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0-20000         18596\n",
       "20000-500000     7412\n",
       "500000+          1067\n",
       "Name: owners, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[\"owners\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reassign_owners_binary(row):\n",
    "    a = [\"20000-50000\", \"50000-100000\", \"100000-200000\", \"200000-500000\"]\n",
    "    b = [\"500000-1000000\", \"1000000-2000000\", \"2000000-5000000\", \"5000000-10000000\", \"10000000-20000000\", \n",
    "         \"20000000-50000000\", \"50000000-100000000\", \"100000000-200000000\"]\n",
    "    if row in a:\n",
    "        row = \"20000+\"\n",
    "    elif row in b:\n",
    "        row = \"20000+\"\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[\"owners\"] = s[\"owners\"].apply(lambda x: reassign_owners_binary(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0-20000         18596\n",
       "20000-500000     7412\n",
       "500000+          1067\n",
       "Name: owners, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[\"owners\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "low >= high",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-306210ea294a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Downsample majority class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mminority_upsampled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminority\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmajority\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#random_state=123\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Combine minority class with downsampled majority class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36mresample\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m    586\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstratify\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_n_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int32\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: low >= high"
     ]
    }
   ],
   "source": [
    "# Deal with scaling\n",
    "majority = s[s['owners'] == \"0-20000\"]\n",
    "minority = s[s['owners'] == \"20000+\"]\n",
    " \n",
    "# Downsample majority class\n",
    "minority_upsampled = resample(minority, n_samples=len(majority)) #random_state=123\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "owners_upsampled_binary = pd.concat([minority_upsampled, majority])\n",
    "\n",
    "owners_upsampled_binary['owners'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_model_binary(platform, genre, category):\n",
    "    # Assign values x\n",
    "    x = owners_upsampled_binary[owners_upsampled_binary[genre]==1]\n",
    "    x = x[x[category]==1]\n",
    "    x.drop([\"appid\", \"name\", \"release_date\",'english', \"developer\", \"publisher\", 'required_age', 'achievements', 'positive_ratings',\n",
    "            'negative_ratings', 'average_playtime', 'median_playtime', 'owners', \"price\"], axis=1, inplace=True)\n",
    "    platforms_copy = platforms.copy()\n",
    "    platforms_copy.remove(platform)\n",
    "    x.drop(platforms_copy, axis=1, inplace=True)\n",
    "    genres_copy = genres.copy()\n",
    "    genres_copy.remove(genre)\n",
    "    x.drop(genres_copy, axis=1, inplace=True)\n",
    "    cat_copy = categories.copy()\n",
    "    cat_copy.remove(category)\n",
    "    x.drop(cat_copy, axis=1, inplace=True)\n",
    "    # Assign values y\n",
    "    y = owners_upsampled_binary[owners_upsampled_binary[genre]==1]\n",
    "    y = y[y[category]==1][\"owners\"]\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "    # Generate the model\n",
    "    model = LogisticRegression(max_iter=1000000).fit(X_train, y_train)\n",
    "    # Get score of the model\n",
    "    score = model.score(X_test,y_test)\n",
    "    # Predict using test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Generate matrix\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"\\nThe expected amounts of sales for this game fall in the range\", list(sp.mode(y_pred)[0])[0])\n",
    "    print(\"With an accuracy score of\", round(score*100, 2), \"%\")\n",
    "    #Data Visualization\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_binary():\n",
    "    print(\"This model will return the predicted number of sales based on key features like platform, genre, and categories.\\n\")\n",
    "    #n = input(\"How many features do you want to test?\")\n",
    "    print(\"\\nPlatforms:\", platforms, \"\\n\")\n",
    "    platform = input(\"Choose Platform:\\n\")\n",
    "    print(\"\\nGenres:\", genres, \"\\n\")\n",
    "    genre = input(\"Choose Genre:\\n\")\n",
    "    print(\"\\nCategories\", categories, \"\\n\")\n",
    "    category = input(\"Choose Category:\\n\")\n",
    "    result = logistic_regression_model_binary(platform, genre, category)\n",
    "    return print(\"\\n\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_binary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** The accuracy hasn't improved much, and I still can't manage to include a visualization. Underwhelming success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include Developer and Publisher in the Model\n",
    "In order to do this, I first have to divide each category in 2 groups. Thus I'm first going to explore the data to decide where I should make the division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[\"developer\"].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_count = s[\"developer\"].value_counts()\n",
    "len(dev_count[dev_count>9])/len(dev_count)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** After trying different options I decide that separating developers by those that have made more than 3 games and the rest seems a good split. My top developors now represent only 5% of my data. I might play with this number in the future. Potentially try it when it represents only 1% of the developers and thus have a clear \"1% has it all\" model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[\"top_developer\"] = 0\n",
    "values = dev_count[dev_count>19].index.tolist()\n",
    "\n",
    "for w in values:\n",
    "    for i in range(len(s)):\n",
    "        if w in s[\"developer\"][i]:\n",
    "            s[\"top_developer\"][i] = 1\n",
    "            \n",
    "s[\"top_developer\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[\"publisher\"].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_count = s[\"publisher\"].value_counts()\n",
    "len(dev_count[dev_count>16])/len(dev_count)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[\"top_publisher\"] = 0\n",
    "values = dev_count[dev_count>49].index.tolist()\n",
    "\n",
    "for w in values:\n",
    "    for i in range(len(s)):\n",
    "        if w in s[\"publisher\"][i]:\n",
    "            s[\"top_publisher\"][i] = 1\n",
    "            \n",
    "s[\"top_publisher\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_model_full(platform, genre, category, developer, publisher):\n",
    "    # Assign values x\n",
    "    x = s[s[genre]==1]\n",
    "    x = x[x[category]==1]\n",
    "    x = x[x[platform]==1]\n",
    "    if developer == \"yes\":\n",
    "        x = x[x[\"top_developer\"]==1]\n",
    "    else:\n",
    "        x = x[x[\"top_developer\"]==0]\n",
    "    if publisher == \"yes\":\n",
    "        x = x[x[\"top_publisher\"]==1]\n",
    "    else:\n",
    "        x = x[x[\"top_publisher\"]==0]\n",
    "    x.drop([\"appid\", \"name\", \"release_date\",'english', \"developer\", \"publisher\", 'required_age', 'achievements', 'positive_ratings',\n",
    "            'negative_ratings', 'average_playtime', 'median_playtime', 'owners', \"price\"], axis=1, inplace=True)\n",
    "    platforms_copy = platforms.copy()\n",
    "    platforms_copy.remove(platform)\n",
    "    x.drop(platforms_copy, axis=1, inplace=True)\n",
    "    genres_copy = genres.copy()\n",
    "    genres_copy.remove(genre)\n",
    "    x.drop(genres_copy, axis=1, inplace=True)\n",
    "    cat_copy = categories.copy()\n",
    "    cat_copy.remove(category)\n",
    "    x.drop(cat_copy, axis=1, inplace=True)\n",
    "    # Assign values y\n",
    "    y = s[s[genre]==1]\n",
    "    y = y[y[category]==1]\n",
    "    y = y[y[platform]==1]\n",
    "    if developer == \"yes\":\n",
    "        y = y[y[\"top_developer\"]==1]\n",
    "    else:\n",
    "        y = y[y[\"top_developer\"]==0]\n",
    "    if publisher == \"yes\":\n",
    "        y = y[y[\"top_publisher\"]==1]\n",
    "    else:\n",
    "        y = y[y[\"top_publisher\"]==0]\n",
    "    y = y[\"owners\"]\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "    # Generate the model\n",
    "    model = LogisticRegression(max_iter=1000000).fit(X_train, y_train)\n",
    "    # Get score of the model\n",
    "    score = model.score(X_test,y_test)\n",
    "    # Predict using test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Generate matrix\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"\\nThe expected amounts of sales for this game fall in the range\", list(sp.mode(y_pred)[0])[0])\n",
    "    print(\"With an accuracy score of\", round(score*100, 2), \"%\")\n",
    "    #Data Visualization\n",
    "    return #plt.plot(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_full():\n",
    "    print(\"This model will return the predicted number of sales based on key features like platform, genre, and categories.\\n\")\n",
    "    #n = input(\"How many features do you want to test?\")\n",
    "    print(\"\\nPlatforms:\", platforms, \"\\n\")\n",
    "    platform = input(\"Choose Platform:\\n\")\n",
    "    print(\"\\nGenres:\", genres, \"\\n\")\n",
    "    genre = input(\"Choose Genre:\\n\")\n",
    "    print(\"\\nCategories\", categories, \"\\n\")\n",
    "    category = input(\"Choose Category:\\n\")\n",
    "    developer = input(\"Has the developer developed 20 games or more?\")\n",
    "    publisher = input(\"Has the publisher published 50 games or more?\")\n",
    "    result = logistic_regression_model_full(platform, genre, category, developer, publisher)\n",
    "    return print(\"\\n\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_full()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** I don't see a significant improvement but I can at least feel that my model is more complete. This is as far as I'm going to go improving this given model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    " \n",
    "y_pred_proba = model.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc_lr = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    " \n",
    "plt.plot(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test, log_model.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
